{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick note:\n",
    "\n",
    "These notes are being written as a Jupyter Notebook, exploiting the fact that you can use different languages in different cells. What you see as notes are written in [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) language. In fact, if you double click on any of these Markdown cells you will see the underlying code (and re-running the cell, e.g., using the Run button, will return to the more pleasent compiled version).<br/>\n",
    "\n",
    "Some other cells are directly written instead in Python (you can see which language each cell is written in in the toolbar of the Jupyter Notebook above!). In this case, you should Run the cell to see its output. None of this should be new to you but it's better to repeat since this is the first part of Year 2.  \n",
    "\n",
    "Also as a reminder, while going through this document, you should be running each cell with Python code because some of their definition are used in subsequent cells and if you do not do that, Python will start raising error messages! \n",
    "\n",
    "In any case, it is good practice sometimes to experiment to see if you have understood correctly. To do that, clear the output cell (selecting Cell-> Current Outputs -> Clear from the toolbar), change something in the base code and re-Run the cell to see how the output changes! \n",
    "\n",
    "================================================================================================================\n",
    "\n",
    "\n",
    "# `pandas`\n",
    "\n",
    "> pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\n",
    "built on top of the Python programming language.\n",
    "\n",
    "We will start this course by introducing a new Python package (collection of pre-defined function and objects) called `pandas`. The description above is from its official website which can be found [here](https://pandas.pydata.org/). <br/>\n",
    "`pandas` contains a wide variety of highly-optimised tools to facilitate the manipulation of big databases, as well as providing a myriad of different input/output management tools.\n",
    "\n",
    "To start, we must install packages and then import them. To install `pandas` we run one of the following commands in the Jupyter Notebook (the specific command depends on our package manager. You should have conda installed but use any of the other two if you get an error):\n",
    "\n",
    "```bash\n",
    "conda install pandas\n",
    "pip install pandas\n",
    "python -m pip install pandas\n",
    "```\n",
    "\n",
    "Following a successful installation, we can import `pandas` using:\n",
    "\n",
    "```python\n",
    "import pandas\n",
    "```\n",
    "\n",
    "====================================================================================================================================\n",
    "\n",
    "**Note: Installing packages in Python can always be done with the general syntax**\n",
    "\n",
    "```python\n",
    "conda install name_of_package\n",
    "```\n",
    "\n",
    "====================================================================================================================================\n",
    "\n",
    "In most of our code we will be importing `numpy`, `pandas` and `matplotlib.pyplot` by default so don't be surprised by this. Something else that we will do is use their commonly accepted abbreivated forms using the `as` statement. Therefore the first few lines of our code will typically look like this:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "In general, it is better **NOT TO use abbreviated names** for packages **EXCEPT** for commonly accepted abbreviated names of packages. This is because unexpected names can make it difficult for other users to read your code. Please bear this in mind throughout the course, and especially when you create your own packages or modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.DataFrame`\n",
    "\n",
    "To begin, we will present the main class that is used in `pandas` and that is the `DataFrame`. Since `DataFrame` is a class, we must call its constructor - `__init__(self, ...)` - by using parentheses - `()` - after we type its name. Let's construct a `DataFrame` now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, not much has happened. This is because we have just created an empty `DataFrame`. There are many ways of initiliasing `DataFrame` objects, and even more ways to use them. In this part of the course we will go through some examples and also provide information on more external examples that show how `DataFrame` objects can be used.\n",
    "\n",
    "One of the main ways of initialising `DataFrame` objects is by passing either a `dict` or `list` to them as the main argument. Here are a few examples:\n",
    "\n",
    "> In these examples you may recognise a new way of printing strings using f-strings which take this format `f\"Text {variable}\"` which can be used to insert a variable into a string. Find more information about f-strings [here](https://www.python.org/dev/peps/pep-0498/)\n",
    "\n",
    "> Note that for improving the readability of the printed strings, we use `'\\n'` characters which are represented as new lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary:\n",
      "{'time': [0.0, 1.0, 2.0, 3.0, 4.0], 'temperature': [37.0, 35.9, 36.0, 37.3, 35.6]}\n",
      "\n",
      "Data from Dictionary:\n",
      "   time  temperature\n",
      "0   0.0         37.0\n",
      "1   1.0         35.9\n",
      "2   2.0         36.0\n",
      "3   3.0         37.3\n",
      "4   4.0         35.6\n",
      "\n",
      "List:\n",
      "[[0.0, 37.0], [1.0, 35.9], [2.0, 36.0], [3.0, 37.3], [4.0, 35.6]]\n",
      "\n",
      "Data from List:\n",
      "     0     1\n",
      "0  0.0  37.0\n",
      "1  1.0  35.9\n",
      "2  2.0  36.0\n",
      "3  3.0  37.3\n",
      "4  4.0  35.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = {\n",
    "    'time' : [0.0, 1.0, 2.0, 3.0, 4.0],\n",
    "    'temperature' : [37.0, 35.9, 36.0, 37.3, 35.6]\n",
    "}\n",
    "\n",
    "print(f\"Dictionary:\\n{data_dict}\\n\")\n",
    "print(f\"Data from Dictionary:\\n{pd.DataFrame(data_dict)}\\n\")\n",
    "\n",
    "data_list = [\n",
    "    [0.0, 37.0],\n",
    "    [1.0, 35.9],\n",
    "    [2.0, 36.0],\n",
    "    [3.0, 37.3],\n",
    "    [4.0, 35.6],\n",
    "]\n",
    "\n",
    "print(f\"List:\\n{data_list}\\n\")\n",
    "print(f\"Data from List:\\n{pd.DataFrame(data_list)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already we can see that `DataFrame` objects present data in a more readable way, and when using dictionaries, the columns gain the titles of the keys from the dictionary. Now that we have constructed our dataframes, we need to know some of their basic functions for data manipulation, so that we can harness them as tools later on in the course.\n",
    "\n",
    "> In the next parts of the course, we will use some of the concepts covered in the first year course MATE40001 with little or no explanation. This is to refresh your memory. One concept that may be new is the use of **annotations** which are exclusive to Python 3 (`def function(args: \"argument annotation\") -> \"return annotation\":`). We will use these without explanation but a description of their use, **which you will be required to know**, can be found [here](https://www.python.org/dev/peps/pep-3107/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32.795705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>36.374262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>36.749039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>32.800396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>29.012655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>27.309292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>30.726343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>36.114951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>37.318667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>34.073380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  temperature\n",
       "0    1    32.795705\n",
       "1    2    36.374262\n",
       "2    3    36.749039\n",
       "3    4    32.800396\n",
       "4    5    29.012655\n",
       "5    6    27.309292\n",
       "6    7    30.726343\n",
       "7    8    36.114951\n",
       "8    9    37.318667\n",
       "9   10    34.073380"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# create a function to generate random data\n",
    "def generate_dataframe(n_rows: int) -> pd.DataFrame:\n",
    "    \"\"\"Generate a DataFrame with time and temperature data\"\"\"\n",
    "    data = {\n",
    "        'day' : range(1, n_rows+1),\n",
    "        'temperature' : [32 + 5*math.sin(i) + random.random() for i in range(n_rows)]\n",
    "    }\n",
    "    result = pd.DataFrame(data)\n",
    "    return result\n",
    "\n",
    "generate_dataframe(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Data\n",
    "\n",
    "We are now going to demonstrate a few different ways of understanding the basic data stored in a `DataFrame`. Firstly to access the names of the columns we access the attribute `data.columns`; and to access the names of the rows, we use the attribute `data.index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:\n",
      "RangeIndex(start=0, stop=10, step=1)\n",
      "Columns:\n",
      "Index(['day', 'temperature'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "temp = generate_dataframe(10)\n",
    "print(f'Index:\\n{temp.index}')\n",
    "print(f'Columns:\\n{temp.columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loc, iloc and indexing\n",
    "One of the most advanced things that `pandas` is capable of is indexing by numerical position or by using strings that refer to the columns of index. Now we shall demonstrate how some of these work. This section is quite complicated and we will revisit indexing `DataFrame` objects throughout the course and show many different examples of how this is done.\n",
    "\n",
    "> The term 'indexing' refers to the act of accessing data within a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `DataFrame.loc` to use `numpy`-like indexing using the <b>actual values</b> in the form of \\[row, column\\]. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day             2.000000\n",
       "temperature    36.980507\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.loc[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32.875117\n",
       "1    36.980507\n",
       "2    36.909371\n",
       "3    33.088624\n",
       "4    28.796627\n",
       "5    28.169348\n",
       "6    31.339406\n",
       "7    35.818383\n",
       "8    37.517344\n",
       "9    34.201856\n",
       "Name: temperature, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.loc[:, 'temperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `DataFrame.iloc` to index the values by their actual position. It is also possible (this is the same between `loc` and `iloc`) to use just one value (rather than two) to access a row by its index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day             2.000000\n",
       "temperature    37.056996\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32.393463\n",
       "1    37.056996\n",
       "2    36.566897\n",
       "3    33.186805\n",
       "4    29.098503\n",
       "5    27.654398\n",
       "6    30.700131\n",
       "7    35.866356\n",
       "8    37.522673\n",
       "9    34.236665\n",
       "Name: temperature, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have strings as the column names, we can select columns by the name of their column. From here we can reindex the returned column (known as a `pd.Series`) to select individual values. Here are some examples of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32.393463\n",
       "1    37.056996\n",
       "2    36.566897\n",
       "3    33.186805\n",
       "4    29.098503\n",
       "5    27.654398\n",
       "6    30.700131\n",
       "7    35.866356\n",
       "8    37.522673\n",
       "9    34.236665\n",
       "Name: temperature, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.0569964812263"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['temperature'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    37.056996\n",
       "2    36.566897\n",
       "3    33.186805\n",
       "4    29.098503\n",
       "5    27.654398\n",
       "Name: temperature, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['temperature'][1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame methods\n",
    "\n",
    "For the next examples, we're going to re-write our `generate_dataframe()` function to add some keyword arguments and we're going to generate some data for each day of the 12 months of the year and store each `DataFrame` as an entry in a dictionary.\n",
    "\n",
    "> Remember that a <b>method</b> is just a <b>function</b> that belongs to a <b>class</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month Names:\n",
      "dict_keys(['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december'])\n",
      "\n",
      "January Weather:\n",
      "    day  temperature\n",
      "0     1    10.210911\n",
      "1     2     9.913583\n",
      "2     3    10.216349\n",
      "3     4     9.738865\n",
      "4     5     9.698485\n",
      "5     6    10.065464\n",
      "6     7     9.723614\n",
      "7     8     9.602762\n",
      "8     9    10.179839\n",
      "9    10     9.532841\n",
      "10   11    10.292285\n",
      "11   12    10.313594\n",
      "12   13     9.784719\n",
      "13   14    10.471105\n",
      "14   15    10.049943\n",
      "15   16    10.403821\n",
      "16   17    10.079736\n",
      "17   18     9.996480\n",
      "18   19    10.168183\n",
      "19   20     9.604798\n",
      "20   21     9.730309\n",
      "21   22    10.218975\n",
      "22   23     9.603863\n",
      "23   24    10.227438\n",
      "24   25    10.178251\n",
      "25   26     9.736987\n",
      "26   27    10.280161\n",
      "27   28     9.595116\n",
      "28   29    10.276092\n",
      "29   30     9.729638\n",
      "30   31     9.622401\n"
     ]
    }
   ],
   "source": [
    "def generate_temperatures(\n",
    "    mean_temperature: float, \n",
    "    days: int, \n",
    "    variation: float = 5.0\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Generate a DataFrame with time and temperature data\"\"\"\n",
    "    data = {\n",
    "        'day' : range(1, days+1),\n",
    "        'temperature' : [mean_temperature + variation * (random.random() - 0.5) for i in range(days)]\n",
    "    }\n",
    "    result = pd.DataFrame(data)\n",
    "    return result\n",
    "\n",
    "months = {\n",
    "    'january' : generate_temperatures(10.0, 31, variation=1.0),\n",
    "    'february' : generate_temperatures(12.0, 28, variation=3.0),\n",
    "    'march' : generate_temperatures(17.0, 31, variation=7.0),\n",
    "    'april' : generate_temperatures(16.0, 30, variation=8.0),\n",
    "    'may' : generate_temperatures(23.0, 31, variation=8.0),\n",
    "    'june' : generate_temperatures(25.0, 30, variation=4.0),\n",
    "    'july' : generate_temperatures(30.0, 31, variation=0.5),\n",
    "    'august' : generate_temperatures(30.0, 31, variation=0.5),\n",
    "    'september' : generate_temperatures(20.0, 30, variation=5.0),\n",
    "    'october' : generate_temperatures(12.0, 31, variation=6.0),\n",
    "    'november' : generate_temperatures(10.0, 30, variation=4.0),\n",
    "    'december' : generate_temperatures(5.0, 31, variation=5.0),\n",
    "}\n",
    "\n",
    "print(f'Month Names:\\n{months.keys()}')\n",
    "print(f\"\\nJanuary Weather:\\n{months['january']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Statistics\n",
    "Now let's use the following built-in methods of the `DataFrame` to do some basic statistics on our data. For reference, here are the methods we are going to use:\n",
    "- `pd.DataFrame.head()` - first 5 rows (or n)\n",
    "- `pd.DataFrame.tail()` - last 5 rows (or n)\n",
    "- `pd.DataFrame.sum()` - sum of each column (use axis=1 for rows)\n",
    "- `pd.DataFrame.mean()` - arithmetic mean\n",
    "- `pd.DataFrame.std()` - standard deviation\n",
    "\n",
    "> For a full list of different `DataFrame` methods, you can look [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head:\n",
      "   day  temperature\n",
      "0    1    10.210911\n",
      "1    2     9.913583\n",
      "2    3    10.216349\n",
      "3    4     9.738865\n",
      "4    5     9.698485\n",
      "\n",
      "Tail:\n",
      "    day  temperature\n",
      "26   27    10.280161\n",
      "27   28     9.595116\n",
      "28   29    10.276092\n",
      "29   30     9.729638\n",
      "30   31     9.622401\n",
      "\n",
      "Sum:\n",
      "day            496.000000\n",
      "temperature    309.246608\n",
      "dtype: float64\n",
      "\n",
      "Mean:\n",
      "day            16.000000\n",
      "temperature     9.975697\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviation:\n",
      "day            9.092121\n",
      "temperature    0.288772\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "january = months['january']\n",
    "print(f'Head:\\n{january.head()}')\n",
    "print(f'\\nTail:\\n{january.tail()}')\n",
    "print(f'\\nSum:\\n{january.sum()}')\n",
    "print(f'\\nMean:\\n{january.mean()}')\n",
    "print(f'\\nStandard Deviation:\\n{january.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some other functions\n",
    "\n",
    "We will now use some more functions to demonstrate how to use `DataFrame` objects. Firstly we will use the `pd.concat` function to create a new large `DataFrame` that contains the temperature for each day of the year, by concatenating (similar to adding) a `list` of `DataFrame` objects together. If we look at the manual for `pd.concat` by typing `help(pd.concat)` we can see which arguments we need:\n",
    "\n",
    "> For most of the large Python projects e.g. numpy, scipy, pandas - the `(help)` function will usually be the same as looking up a function in the official documentation - it is essential to be able to look up the definitions of functions and classes when there is no-one to ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function concat in module pandas.core.reshape.concat:\n",
      "\n",
      "concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=None, copy=True)\n",
      "    Concatenate pandas objects along a particular axis with optional set logic\n",
      "    along the other axes.\n",
      "    \n",
      "    Can also add a layer of hierarchical indexing on the concatenation axis,\n",
      "    which may be useful if the labels are the same (or overlapping) on\n",
      "    the passed axis number.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    objs : a sequence or mapping of Series, DataFrame, or Panel objects\n",
      "        If a dict is passed, the sorted keys will be used as the `keys`\n",
      "        argument, unless it is passed, in which case the values will be\n",
      "        selected (see below). Any None objects will be dropped silently unless\n",
      "        they are all None in which case a ValueError will be raised\n",
      "    axis : {0/'index', 1/'columns'}, default 0\n",
      "        The axis to concatenate along\n",
      "    join : {'inner', 'outer'}, default 'outer'\n",
      "        How to handle indexes on other axis(es)\n",
      "    join_axes : list of Index objects\n",
      "        Specific indexes to use for the other n - 1 axes instead of performing\n",
      "        inner/outer set logic\n",
      "    ignore_index : boolean, default False\n",
      "        If True, do not use the index values along the concatenation axis. The\n",
      "        resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n",
      "        concatenating objects where the concatenation axis does not have\n",
      "        meaningful indexing information. Note the index values on the other\n",
      "        axes are still respected in the join.\n",
      "    keys : sequence, default None\n",
      "        If multiple levels passed, should contain tuples. Construct\n",
      "        hierarchical index using the passed keys as the outermost level\n",
      "    levels : list of sequences, default None\n",
      "        Specific levels (unique values) to use for constructing a\n",
      "        MultiIndex. Otherwise they will be inferred from the keys\n",
      "    names : list, default None\n",
      "        Names for the levels in the resulting hierarchical index\n",
      "    verify_integrity : boolean, default False\n",
      "        Check whether the new concatenated axis contains duplicates. This can\n",
      "        be very expensive relative to the actual data concatenation\n",
      "    sort : boolean, default None\n",
      "        Sort non-concatenation axis if it is not already aligned when `join`\n",
      "        is 'outer'. The current default of sorting is deprecated and will\n",
      "        change to not-sorting in a future version of pandas.\n",
      "    \n",
      "        Explicitly pass ``sort=True`` to silence the warning and sort.\n",
      "        Explicitly pass ``sort=False`` to silence the warning and not sort.\n",
      "    \n",
      "        This has no effect when ``join='inner'``, which already preserves\n",
      "        the order of the non-concatenation axis.\n",
      "    \n",
      "        .. versionadded:: 0.23.0\n",
      "    \n",
      "    copy : boolean, default True\n",
      "        If False, do not copy data unnecessarily\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    concatenated : object, type of objs\n",
      "        When concatenating all ``Series`` along the index (axis=0), a\n",
      "        ``Series`` is returned. When ``objs`` contains at least one\n",
      "        ``DataFrame``, a ``DataFrame`` is returned. When concatenating along\n",
      "        the columns (axis=1), a ``DataFrame`` is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    Series.append\n",
      "    DataFrame.append\n",
      "    DataFrame.join\n",
      "    DataFrame.merge\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The keys, levels, and names arguments are all optional.\n",
      "    \n",
      "    A walkthrough of how this method fits in with other tools for combining\n",
      "    pandas objects can be found `here\n",
      "    <http://pandas.pydata.org/pandas-docs/stable/merging.html>`__.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Combine two ``Series``.\n",
      "    \n",
      "    >>> s1 = pd.Series(['a', 'b'])\n",
      "    >>> s2 = pd.Series(['c', 'd'])\n",
      "    >>> pd.concat([s1, s2])\n",
      "    0    a\n",
      "    1    b\n",
      "    0    c\n",
      "    1    d\n",
      "    dtype: object\n",
      "    \n",
      "    Clear the existing index and reset it in the result\n",
      "    by setting the ``ignore_index`` option to ``True``.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], ignore_index=True)\n",
      "    0    a\n",
      "    1    b\n",
      "    2    c\n",
      "    3    d\n",
      "    dtype: object\n",
      "    \n",
      "    Add a hierarchical index at the outermost level of\n",
      "    the data with the ``keys`` option.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], keys=['s1', 's2',])\n",
      "    s1  0    a\n",
      "        1    b\n",
      "    s2  0    c\n",
      "        1    d\n",
      "    dtype: object\n",
      "    \n",
      "    Label the index keys you create with the ``names`` option.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], keys=['s1', 's2'],\n",
      "    ...           names=['Series name', 'Row ID'])\n",
      "    Series name  Row ID\n",
      "    s1           0         a\n",
      "                 1         b\n",
      "    s2           0         c\n",
      "                 1         d\n",
      "    dtype: object\n",
      "    \n",
      "    Combine two ``DataFrame`` objects with identical columns.\n",
      "    \n",
      "    >>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
      "    ...                    columns=['letter', 'number'])\n",
      "    >>> df1\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    >>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n",
      "    ...                    columns=['letter', 'number'])\n",
      "    >>> df2\n",
      "      letter  number\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    >>> pd.concat([df1, df2])\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    \n",
      "    Combine ``DataFrame`` objects with overlapping columns\n",
      "    and return everything. Columns outside the intersection will\n",
      "    be filled with ``NaN`` values.\n",
      "    \n",
      "    >>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n",
      "    ...                    columns=['letter', 'number', 'animal'])\n",
      "    >>> df3\n",
      "      letter  number animal\n",
      "    0      c       3    cat\n",
      "    1      d       4    dog\n",
      "    >>> pd.concat([df1, df3], sort=False)\n",
      "      letter  number animal\n",
      "    0      a       1    NaN\n",
      "    1      b       2    NaN\n",
      "    0      c       3    cat\n",
      "    1      d       4    dog\n",
      "    \n",
      "    Combine ``DataFrame`` objects with overlapping columns\n",
      "    and return only those that are shared by passing ``inner`` to\n",
      "    the ``join`` keyword argument.\n",
      "    \n",
      "    >>> pd.concat([df1, df3], join=\"inner\")\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    \n",
      "    Combine ``DataFrame`` objects horizontally along the x axis by\n",
      "    passing in ``axis=1``.\n",
      "    \n",
      "    >>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n",
      "    ...                    columns=['animal', 'name'])\n",
      "    >>> pd.concat([df1, df4], axis=1)\n",
      "      letter  number  animal    name\n",
      "    0      a       1    bird   polly\n",
      "    1      b       2  monkey  george\n",
      "    \n",
      "    Prevent the result from including duplicate index values with the\n",
      "    ``verify_integrity`` option.\n",
      "    \n",
      "    >>> df5 = pd.DataFrame([1], index=['a'])\n",
      "    >>> df5\n",
      "       0\n",
      "    a  1\n",
      "    >>> df6 = pd.DataFrame([2], index=['a'])\n",
      "    >>> df6\n",
      "       0\n",
      "    a  2\n",
      "    >>> pd.concat([df5, df6], verify_integrity=True)\n",
      "    Traceback (most recent call last):\n",
      "        ...\n",
      "    ValueError: Indexes have overlapping values: ['a']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument is called `objs` which is described as a sequence or mapping of different objects (one of which is `DataFrame`. So we will use the `dict.values()` method as the argument since this returns a sequence of our values, all of which are `DataFrame` objects. We will also use the keyword argument `ignore_index=True` since for us, it is important for the `index` to be in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:\n",
      "\n",
      "   day  temperature\n",
      "0    1    10.210911\n",
      "1    2     9.913583\n",
      "2    3    10.216349\n",
      "3    4     9.738865\n",
      "4    5     9.698485\n",
      "...\n",
      "     day  temperature\n",
      "360   27     4.847370\n",
      "361   28     3.049918\n",
      "362   29     6.433475\n",
      "363   30     5.130456\n",
      "364   31     2.977165\n"
     ]
    }
   ],
   "source": [
    "year = pd.concat(months.values(), ignore_index=True)\n",
    "print(f'Year:\\n\\n{year.head()}\\n...\\n{year.tail()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column of a `DataFrame` is called a `Series` and we will now set the `day` column to the correct values by setting it to the `index` of the `DataFrame`. By calling `year.tail()` we can now see that the days have been updated to be the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>361</td>\n",
       "      <td>4.847370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>362</td>\n",
       "      <td>3.049918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>363</td>\n",
       "      <td>6.433475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>364</td>\n",
       "      <td>5.130456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>365</td>\n",
       "      <td>2.977165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     day  temperature\n",
       "360  361     4.847370\n",
       "361  362     3.049918\n",
       "362  363     6.433475\n",
       "363  364     5.130456\n",
       "364  365     2.977165"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year['day'] = year.index + 1\n",
    "year.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We have now covered some of the basics of using `pd.DataFrame` objects. Through completing some of the tasks and by using `DataFrame` objects to manage our data throughout the course, we will learn some of their many uses, and provide experience in looking through documentation and the internet to figure out how we can use our `DataFrame` objects for the purpose that is required.\n",
    "\n",
    "Aside from learning about `pandas` and `DataFrame` objects, we have also covered (and in some cases revisited) the following topics:\n",
    "\n",
    "- f-strings\n",
    "- Function arguments and keyword-arguments\n",
    "- Function annotations\n",
    "- Indexing\n",
    "- Variables, attributes, functions and methods\n",
    "- `list` and `dict`\n",
    "- `import` ... `as` ..."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
